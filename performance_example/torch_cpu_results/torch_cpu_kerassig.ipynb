{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5510d0e-d0d8-4070-ab2c-6071a4d2efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.7.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (2.2.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.5.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting triton==3.1.0\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.12.0 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9e2347-be9e-4353-9449-3801a64503a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_sig in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: keras<4.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from keras_sig) (3.7.0)\n",
      "Requirement already satisfied: jaxtyping<0.3.0,>=0.2.36 in /usr/local/lib/python3.10/dist-packages (from keras_sig) (0.2.36)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (24.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (3.12.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (2.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (0.13.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (0.0.8)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (13.9.4)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras<4.0,>=3.0.0->keras_sig) (0.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras<4.0,>=3.0.0->keras_sig) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras<4.0,>=3.0.0->keras_sig) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras<4.0,>=3.0.0->keras_sig) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras<4.0,>=3.0.0->keras_sig) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras_sig pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c7b2d0-dd6a-474d-b7b2-1f7a2cfc0053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing access to CUDA device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Keras and backend configuration\n",
    "BACKEND = 'torch'\n",
    "os.environ['KERAS_BACKEND'] = BACKEND\n",
    "\n",
    "print('removing access to CUDA device')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"JAX_PLATFORMS\"]=\"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb465d7-6f9c-4b53-a755-f9e467d7f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch signature benchmarks...\n",
      "PyTorch CUDA Available: False\n",
      "\n",
      "Varying batch size...\n",
      "Completed batch_size=32\n",
      "Completed batch_size=64\n",
      "Completed batch_size=128\n",
      "Completed batch_size=256\n",
      "Completed batch_size=512\n",
      "\n",
      "Varying sequence length...\n",
      "Completed seq_len=50\n",
      "Completed seq_len=100\n",
      "Completed seq_len=200\n",
      "Completed seq_len=500\n",
      "Completed seq_len=1000\n",
      "\n",
      "Varying depth...\n",
      "Completed depth=2\n",
      "Completed depth=3\n",
      "Completed depth=4\n",
      "Completed depth=5\n",
      "Completed depth=6\n",
      "\n",
      "Benchmarks complete. Results saved to CSV.\n",
      "\n",
      "System information:\n",
      "cpu_info: AMD Ryzen 9 5900X 12-Core Processor\n",
      "pytorch_version: 2.5.1+cu124\n",
      "keras_sig_version: 1.0.2\n",
      "cuda_available: False\n",
      "gpu_device: None\n",
      "cuda_version: None\n",
      "timestamp: 20250105_163733\n",
      "system: Linux\n",
      "python_version: 3.10.12\n",
      "platform: Linux-6.8.0-45-generic-x86_64-with-glibc2.35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>n_features</th>\n",
       "      <th>depth</th>\n",
       "      <th>compilation_time</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.991604</td>\n",
       "      <td>1.471663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.605677</td>\n",
       "      <td>2.927780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.282713</td>\n",
       "      <td>3.965688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.016659</td>\n",
       "      <td>6.830716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12.342930</td>\n",
       "      <td>12.337351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.187014</td>\n",
       "      <td>1.624846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.614975</td>\n",
       "      <td>2.113104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.787279</td>\n",
       "      <td>4.548478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13.433933</td>\n",
       "      <td>14.608765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31.124592</td>\n",
       "      <td>32.256675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.822306</td>\n",
       "      <td>0.601220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.119137</td>\n",
       "      <td>1.115799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.198219</td>\n",
       "      <td>1.878691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9.627581</td>\n",
       "      <td>5.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>23.892641</td>\n",
       "      <td>25.092864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size  seq_len  n_features  depth  compilation_time  execution_time\n",
       "0           32      100           3      4          3.991604        1.471663\n",
       "1           64      100           3      4          2.605677        2.927780\n",
       "2          128      100           3      4          4.282713        3.965688\n",
       "3          256      100           3      4          7.016659        6.830716\n",
       "4          512      100           3      4         12.342930       12.337351\n",
       "5          128       50           3      4          2.187014        1.624846\n",
       "6          128      100           3      4          2.614975        2.113104\n",
       "7          128      200           3      4          3.787279        4.548478\n",
       "8          128      500           3      4         13.433933       14.608765\n",
       "9          128     1000           3      4         31.124592       32.256675\n",
       "10         128      100           3      2          0.822306        0.601220\n",
       "11         128      100           3      3          1.119137        1.115799\n",
       "12         128      100           3      4          2.198219        1.878691\n",
       "13         128      100           3      5          9.627581        5.249929\n",
       "14         128      100           3      6         23.892641       25.092864"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import platform\n",
    "from typing import Callable, List, Dict\n",
    "import keras_sig\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "def get_cpu_info():\n",
    "    if platform.system() == \"Linux\":\n",
    "        try:\n",
    "            with open('/proc/cpuinfo', 'r') as f:\n",
    "                for line in f:\n",
    "                    if 'model name' in line:\n",
    "                        return line.split(':')[1].strip()\n",
    "        except:\n",
    "            pass\n",
    "    return platform.processor() or platform.machine()\n",
    "\n",
    "def time_function(func: Callable, number: int = 10) -> float:\n",
    "    \"\"\"Time a function over multiple runs and return average time in milliseconds\"\"\"\n",
    "    # First call to compile\n",
    "    compilation_start = time.time()\n",
    "    _ = func()\n",
    "    compilation_time = (time.time() - compilation_start) * 1000\n",
    "    \n",
    "    # Subsequent calls for execution time\n",
    "    times = []\n",
    "    for _ in range(number):\n",
    "        start = time.time()\n",
    "        _ = func()\n",
    "        times.append((time.time() - start) * 1000)  # Convert to milliseconds\n",
    "    \n",
    "    return compilation_time, np.mean(times)\n",
    "\n",
    "def run_benchmark(batch_size: int, seq_len: int, n_features: int, depth: int) -> Dict:\n",
    "    \"\"\"Run benchmark for a specific configuration\"\"\"\n",
    "    \n",
    "    # Generate paths\n",
    "    paths = np.random.randn(batch_size, seq_len, n_features).astype(np.float32)\n",
    "    paths_torch = torch.from_numpy(paths)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        paths_torch = paths_torch.cuda()\n",
    "    \n",
    "    # Time implementation with explicit compilation and execution times\n",
    "    compilation_time, execution_time = time_function(\n",
    "        lambda: keras_sig.signature(paths_torch, depth)\n",
    "    )\n",
    "    \n",
    "    results = {\n",
    "        'batch_size': batch_size,\n",
    "        'seq_len': seq_len,\n",
    "        'n_features': n_features,\n",
    "        'depth': depth,\n",
    "        'compilation_time': compilation_time,\n",
    "        'execution_time': execution_time\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_parameter_sweep():\n",
    "    \"\"\"Run benchmarks varying one parameter at a time\"\"\"\n",
    "    \n",
    "    # Default parameters\n",
    "    default_batch_size = 128\n",
    "    default_seq_len = 100\n",
    "    default_n_features = 3\n",
    "    default_depth = 4\n",
    "    \n",
    "    # Parameter ranges\n",
    "    batch_sizes = [32, 64, 128, 256, 512]\n",
    "    seq_lens = [50, 100, 200, 500, 1000]\n",
    "    depths = [2, 3, 4, 5, 6]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Display PyTorch configuration\n",
    "    is_gpu = torch.cuda.is_available()\n",
    "    print(\"PyTorch CUDA Available:\", is_gpu)\n",
    "    if is_gpu:\n",
    "        print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "    # Vary batch size\n",
    "    print(\"\\nVarying batch size...\")\n",
    "    for batch_size in batch_sizes:\n",
    "        result = run_benchmark(\n",
    "            batch_size=batch_size,\n",
    "            seq_len=default_seq_len,\n",
    "            n_features=default_n_features,\n",
    "            depth=default_depth\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"Completed batch_size={batch_size}\")\n",
    "    \n",
    "    # Vary sequence length\n",
    "    print(\"\\nVarying sequence length...\")\n",
    "    for seq_len in seq_lens:\n",
    "        result = run_benchmark(\n",
    "            batch_size=default_batch_size,\n",
    "            seq_len=seq_len,\n",
    "            n_features=default_n_features,\n",
    "            depth=default_depth\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"Completed seq_len={seq_len}\")\n",
    "    \n",
    "    # Vary depth\n",
    "    print(\"\\nVarying depth...\")\n",
    "    for depth in depths:\n",
    "        result = run_benchmark(\n",
    "            batch_size=default_batch_size,\n",
    "            seq_len=default_seq_len,\n",
    "            n_features=default_n_features,\n",
    "            depth=depth\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"Completed depth={depth}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    device_type = \"gpu\" if is_gpu else \"cpu\"\n",
    "    csv_filename = f'pytorch_signature_benchmarks_{device_type}_{timestamp}.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    # Save metadata about the system\n",
    "    metadata = {\n",
    "        'cpu_info': get_cpu_info(),\n",
    "        'pytorch_version': torch.__version__,\n",
    "        'keras_sig_version': '1.0.2',\n",
    "        'cuda_available': is_gpu,\n",
    "        'gpu_device': torch.cuda.get_device_name(0) if is_gpu else None,\n",
    "        'cuda_version': torch.version.cuda if is_gpu else None,\n",
    "        'timestamp': timestamp,\n",
    "        'system': platform.system(),\n",
    "        'python_version': platform.python_version(),\n",
    "        'platform': platform.platform()\n",
    "    }\n",
    "    \n",
    "    with open(f'pytorch_signature_benchmarks_{device_type}_metadata_{timestamp}.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    return df, metadata\n",
    "\n",
    "print(\"Starting PyTorch signature benchmarks...\")\n",
    "df, metadata = run_parameter_sweep()\n",
    "print(\"\\nBenchmarks complete. Results saved to CSV.\")\n",
    "print(\"\\nSystem information:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91267d3-9ae2-47de-87c1-656c46cf10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Keras signature benchmarks...\n",
      "\n",
      "Run 1/48\n",
      "Parameters: seq_len=100, sig_input_size=2, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 2/48\n",
      "Parameters: seq_len=100, sig_input_size=2, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 3/48\n",
      "Parameters: seq_len=100, sig_input_size=2, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 4/48\n",
      "Parameters: seq_len=100, sig_input_size=4, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 5/48\n",
      "Parameters: seq_len=100, sig_input_size=4, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 6/48\n",
      "Parameters: seq_len=100, sig_input_size=4, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 7/48\n",
      "Parameters: seq_len=100, sig_input_size=6, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 8/48\n",
      "Parameters: seq_len=100, sig_input_size=6, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 9/48\n",
      "Parameters: seq_len=100, sig_input_size=6, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 10/48\n",
      "Parameters: seq_len=100, sig_input_size=10, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 11/48\n",
      "Parameters: seq_len=100, sig_input_size=10, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 12/48\n",
      "Parameters: seq_len=100, sig_input_size=10, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 13/48\n",
      "Parameters: seq_len=200, sig_input_size=2, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 14/48\n",
      "Parameters: seq_len=200, sig_input_size=2, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 15/48\n",
      "Parameters: seq_len=200, sig_input_size=2, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 16/48\n",
      "Parameters: seq_len=200, sig_input_size=4, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 17/48\n",
      "Parameters: seq_len=200, sig_input_size=4, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 18/48\n",
      "Parameters: seq_len=200, sig_input_size=4, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 19/48\n",
      "Parameters: seq_len=200, sig_input_size=6, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 20/48\n",
      "Parameters: seq_len=200, sig_input_size=6, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 21/48\n",
      "Parameters: seq_len=200, sig_input_size=6, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 22/48\n",
      "Parameters: seq_len=200, sig_input_size=10, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 23/48\n",
      "Parameters: seq_len=200, sig_input_size=10, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 24/48\n",
      "Parameters: seq_len=200, sig_input_size=10, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 25/48\n",
      "Parameters: seq_len=350, sig_input_size=2, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 26/48\n",
      "Parameters: seq_len=350, sig_input_size=2, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 27/48\n",
      "Parameters: seq_len=350, sig_input_size=2, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 28/48\n",
      "Parameters: seq_len=350, sig_input_size=4, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 29/48\n",
      "Parameters: seq_len=350, sig_input_size=4, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 30/48\n",
      "Parameters: seq_len=350, sig_input_size=4, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 31/48\n",
      "Parameters: seq_len=350, sig_input_size=6, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 32/48\n",
      "Parameters: seq_len=350, sig_input_size=6, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 33/48\n",
      "Parameters: seq_len=350, sig_input_size=6, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 34/48\n",
      "Parameters: seq_len=350, sig_input_size=10, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 35/48\n",
      "Parameters: seq_len=350, sig_input_size=10, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 36/48\n",
      "Parameters: seq_len=350, sig_input_size=10, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 37/48\n",
      "Parameters: seq_len=500, sig_input_size=2, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 38/48\n",
      "Parameters: seq_len=500, sig_input_size=2, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 39/48\n",
      "Parameters: seq_len=500, sig_input_size=2, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 40/48\n",
      "Parameters: seq_len=500, sig_input_size=4, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 41/48\n",
      "Parameters: seq_len=500, sig_input_size=4, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 42/48\n",
      "Parameters: seq_len=500, sig_input_size=4, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 43/48\n",
      "Parameters: seq_len=500, sig_input_size=6, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 44/48\n",
      "Parameters: seq_len=500, sig_input_size=6, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 45/48\n",
      "Parameters: seq_len=500, sig_input_size=6, depth=4, implementation=keras_sig\n",
      "\n",
      "Run 46/48\n",
      "Parameters: seq_len=500, sig_input_size=10, depth=2, implementation=keras_sig\n",
      "\n",
      "Run 47/48\n",
      "Parameters: seq_len=500, sig_input_size=10, depth=3, implementation=keras_sig\n",
      "\n",
      "Run 48/48\n",
      "Parameters: seq_len=500, sig_input_size=10, depth=4, implementation=keras_sig\n",
      "\n",
      "Benchmarks complete. Results saved to CSV and JSON files.\n",
      "\n",
      "System information:\n",
      "cpu_info: AMD Ryzen 9 5900X 12-Core Processor\n",
      "keras_backend: torch\n",
      "keras_version: 3.7.0\n",
      "keras_sig_version: 1.0.2\n",
      "timestamp: 20250105_202014\n",
      "system: Linux\n",
      "python_version: 3.10.12\n",
      "platform: Linux-6.8.0-45-generic-x86_64-with-glibc2.35\n",
      "batch_size: 128\n",
      "n_feature: 20\n",
      "n_ahead: 10\n",
      "epochs: 10\n",
      "\n",
      "Benchmark Results:\n",
      "    seq_len  sig_input_size  depth implementation  compilation_time  \\\n",
      "0       100               2      2      keras_sig          0.006182   \n",
      "1       100               2      3      keras_sig          0.007320   \n",
      "2       100               2      4      keras_sig          0.008950   \n",
      "3       100               4      2      keras_sig          0.005975   \n",
      "4       100               4      3      keras_sig          0.007333   \n",
      "5       100               4      4      keras_sig          0.009301   \n",
      "6       100               6      2      keras_sig          0.006168   \n",
      "7       100               6      3      keras_sig          0.007410   \n",
      "8       100               6      4      keras_sig          0.009351   \n",
      "9       100              10      2      keras_sig          0.006048   \n",
      "10      100              10      3      keras_sig          0.007587   \n",
      "11      100              10      4      keras_sig          0.010282   \n",
      "12      200               2      2      keras_sig          0.005961   \n",
      "13      200               2      3      keras_sig          0.007435   \n",
      "14      200               2      4      keras_sig          0.009210   \n",
      "15      200               4      2      keras_sig          0.006037   \n",
      "16      200               4      3      keras_sig          0.007497   \n",
      "17      200               4      4      keras_sig          0.009136   \n",
      "18      200               6      2      keras_sig          0.006137   \n",
      "19      200               6      3      keras_sig          0.007465   \n",
      "20      200               6      4      keras_sig          0.009501   \n",
      "21      200              10      2      keras_sig          0.006073   \n",
      "22      200              10      3      keras_sig          0.007580   \n",
      "23      200              10      4      keras_sig          0.010464   \n",
      "24      350               2      2      keras_sig          0.005769   \n",
      "25      350               2      3      keras_sig          0.007011   \n",
      "26      350               2      4      keras_sig          0.008658   \n",
      "27      350               4      2      keras_sig          0.005800   \n",
      "28      350               4      3      keras_sig          0.007075   \n",
      "29      350               4      4      keras_sig          0.008760   \n",
      "30      350               6      2      keras_sig          0.005832   \n",
      "31      350               6      3      keras_sig          0.007239   \n",
      "32      350               6      4      keras_sig          0.009460   \n",
      "33      350              10      2      keras_sig          0.006051   \n",
      "34      350              10      3      keras_sig          0.007595   \n",
      "35      350              10      4      keras_sig          0.011396   \n",
      "36      500               2      2      keras_sig          0.006259   \n",
      "37      500               2      3      keras_sig          0.007432   \n",
      "38      500               2      4      keras_sig          0.009346   \n",
      "39      500               4      2      keras_sig          0.006237   \n",
      "40      500               4      3      keras_sig          0.007294   \n",
      "41      500               4      4      keras_sig          0.009526   \n",
      "42      500               6      2      keras_sig          0.006066   \n",
      "43      500               6      3      keras_sig          0.007492   \n",
      "44      500               6      4      keras_sig          0.009551   \n",
      "45      500              10      2      keras_sig          0.006044   \n",
      "46      500              10      3      keras_sig          0.007845   \n",
      "47      500              10      4      keras_sig          0.013061   \n",
      "\n",
      "    training_time  avg_epoch_time  final_loss  \n",
      "0        3.752984        0.375298    1.152372  \n",
      "1        5.359849        0.535985    2.058499  \n",
      "2        7.621485        0.762148   13.545354  \n",
      "3        3.749320        0.374932    1.168072  \n",
      "4        5.690246        0.569025    1.523035  \n",
      "5       18.637815        1.863782    4.133683  \n",
      "6        3.846928        0.384693    1.239373  \n",
      "7        9.536918        0.953692    1.324058  \n",
      "8      120.010079       12.001008    4.706621  \n",
      "9        4.271804        0.427180    1.161297  \n",
      "10      83.582808        8.358281    1.272151  \n",
      "11     890.892000       89.089200    6.148781  \n",
      "12       4.437438        0.443744    1.177343  \n",
      "13       6.473307        0.647331    3.859605  \n",
      "14       9.320140        0.932014   34.736031  \n",
      "15       4.274209        0.427421    1.227515  \n",
      "16       7.638109        0.763811    3.123729  \n",
      "17      38.217000        3.821700   65.301834  \n",
      "18       4.798104        0.479810    1.362852  \n",
      "19      28.096935        2.809693    2.380044  \n",
      "20     251.726339       25.172634   18.440771  \n",
      "21       7.982760        0.798276    1.235853  \n",
      "22     167.837533       16.783753    1.399104  \n",
      "23    1747.700750      174.770075   29.581167  \n",
      "24       5.122762        0.512276    3.217107  \n",
      "25       7.699525        0.769952    4.531522  \n",
      "26      11.439976        1.143998   94.677284  \n",
      "27       5.345308        0.534531    1.236095  \n",
      "28      14.818670        1.481867    3.928097  \n",
      "29     101.193006       10.119301   80.718018  \n",
      "30       6.617649        0.661765    1.439398  \n",
      "31      64.513279        6.451328    1.670960  \n",
      "32     465.440027       46.544003   91.552231  \n",
      "33      16.278500        1.627850    1.339159  \n",
      "34     302.896471       30.289647    1.604436  \n",
      "35    3026.896576      302.689658   60.113758  \n",
      "36       5.825321        0.582532    2.325969  \n",
      "37       9.148166        0.914817    6.353347  \n",
      "38      14.338244        1.433824   70.501198  \n",
      "39       6.683667        0.668367    2.403780  \n",
      "40      28.642048        2.864205    8.281586  \n",
      "41     153.452270       15.345227  249.978302  \n",
      "42       9.513081        0.951308    1.863916  \n",
      "43     100.529612       10.052961    1.925914  \n",
      "44     674.456915       67.445692  143.816666  \n",
      "45      25.467024        2.546702    1.300658  \n",
      "46     434.382197       43.438220    2.151537  \n",
      "47    4353.571126      435.357113  201.589325  \n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import platform\n",
    "\n",
    "def get_cpu_info():\n",
    "    if platform.system() == \"Linux\":\n",
    "        try:\n",
    "            with open('/proc/cpuinfo', 'r') as f:\n",
    "                for line in f:\n",
    "                    if 'model name' in line:\n",
    "                        return line.split(':')[1].strip()\n",
    "        except:\n",
    "            pass\n",
    "    return platform.processor() or platform.machine()\n",
    "\n",
    "class SigNet(keras.Model):\n",
    "    def __init__(self, in_channels, out_dimension, sig_input_size, sig_depth, sig_layer_class):\n",
    "        super().__init__()\n",
    "        self.dense1 = keras.layers.Dense(sig_input_size)\n",
    "        self.signature = sig_layer_class(depth=sig_depth)\n",
    "        self.linear = keras.layers.Dense(out_dimension)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        dense_out = self.dense1(inputs)\n",
    "        y = self.signature(dense_out)\n",
    "        z = self.linear(y)\n",
    "        return z\n",
    "\n",
    "def create_data(num_sample, seq_len, n_feature, n_ahead):\n",
    "    X = np.random.randn(num_sample, seq_len, n_feature).astype(np.float32)\n",
    "    y = np.random.randn(num_sample, n_ahead).astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "def measure_compilation_time(model, X, y, batch_size):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"mse\",\n",
    "        jit_compile=False\n",
    "    )\n",
    "    \n",
    "    # Time the first prediction which triggers compilation\n",
    "    sample_X = X[:1]  # Take just one sample\n",
    "    \n",
    "    compilation_start = time.time()\n",
    "    model.predict(sample_X, verbose=0)  # First prediction triggers compilation\n",
    "    compilation_time = time.time() - compilation_start\n",
    "    \n",
    "    return compilation_time\n",
    "\n",
    "def train_model(model, X, y, batch_size, epochs=10):\n",
    "    # Time the actual training\n",
    "    training_start = time.time()\n",
    "    history = model.fit(\n",
    "        X, y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=0\n",
    "    )\n",
    "    training_time = time.time() - training_start\n",
    "    \n",
    "    return {\n",
    "        'final_loss': float(history.history['loss'][-1]),\n",
    "        'training_time': training_time,\n",
    "        'avg_epoch_time': training_time/epochs\n",
    "    }\n",
    "\n",
    "def run_benchmarks():\n",
    "    # Parameters to test\n",
    "    seq_lens = [100, 200, 350, 500]\n",
    "    sig_input_sizes = [2, 4, 6, 10]\n",
    "    depths = [2, 3, 4]\n",
    "    \n",
    "    # Fixed parameters\n",
    "    batch_size = 128\n",
    "    n_feature = 20\n",
    "    n_ahead = 10\n",
    "    epochs = 10\n",
    "    \n",
    "    results = []\n",
    "    sig_layers = {\n",
    "        'keras_sig': keras_sig.SigLayer,\n",
    "    }\n",
    "    \n",
    "    total_runs = len(seq_lens) * len(sig_input_sizes) * len(depths) * len(sig_layers)\n",
    "    current_run = 0\n",
    "    \n",
    "    for seq_len in seq_lens:\n",
    "        num_sample = batch_size * 100 - 35  # Not exactly divisible by batch size\n",
    "        \n",
    "        for sig_input_size in sig_input_sizes:\n",
    "            for depth in depths:\n",
    "                for layer_name, layer_class in sig_layers.items():\n",
    "                    current_run += 1\n",
    "                    print(f\"\\nRun {current_run}/{total_runs}\")\n",
    "                    print(f\"Parameters: seq_len={seq_len}, sig_input_size={sig_input_size}, depth={depth}, implementation={layer_name}\")\n",
    "                    \n",
    "                    # Create data\n",
    "                    X, y = create_data(num_sample, seq_len, n_feature, n_ahead)\n",
    "                    \n",
    "                    # Create model\n",
    "                    model = SigNet(n_feature, n_ahead, sig_input_size, depth, layer_class)\n",
    "                    \n",
    "                    # Measure compilation time\n",
    "                    compilation_time = measure_compilation_time(model, X, y, batch_size)\n",
    "                    \n",
    "                    # Train model and measure training time\n",
    "                    training_results = train_model(model, X, y, batch_size, epochs)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'seq_len': seq_len,\n",
    "                        'sig_input_size': sig_input_size,\n",
    "                        'depth': depth,\n",
    "                        'implementation': layer_name,\n",
    "                        'compilation_time': compilation_time,\n",
    "                        'training_time': training_results['training_time'],\n",
    "                        'avg_epoch_time': training_results['avg_epoch_time'],\n",
    "                        'final_loss': training_results['final_loss']\n",
    "                    })\n",
    "                    # Clear model and free memory\n",
    "                    del model\n",
    "                    keras.backend.clear_session()\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    device_type = \"gpu\" if keras.backend.backend() == \"jax\" else \"cpu\"\n",
    "    \n",
    "    # Save benchmark results\n",
    "    csv_filename = f'keras_benchmarks_{device_type}_{timestamp}.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'cpu_info': get_cpu_info(),\n",
    "        'keras_backend': keras.backend.backend(),\n",
    "        'keras_version': keras.__version__,\n",
    "        'keras_sig_version': '1.0.2',\n",
    "        'timestamp': timestamp,\n",
    "        'system': platform.system(),\n",
    "        'python_version': platform.python_version(),\n",
    "        'platform': platform.platform(),\n",
    "        'batch_size': batch_size,\n",
    "        'n_feature': n_feature,\n",
    "        'n_ahead': n_ahead,\n",
    "        'epochs': epochs\n",
    "    }\n",
    "    \n",
    "    with open(f'keras_torch_benchmarks_{device_type}_metadata_{timestamp}.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    return df, metadata\n",
    "\n",
    "print(\"Starting Keras signature benchmarks...\")\n",
    "df, metadata = run_benchmarks()\n",
    "print(\"\\nBenchmarks complete. Results saved to CSV and JSON files.\")\n",
    "print(\"\\nSystem information:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Display results\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\\nBenchmark Results:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd7cbd-8ee3-4e66-982e-733a7be293d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
